{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c755300",
   "metadata": {},
   "source": [
    "# Topic Analysis of CRINK Voting Patterns\n",
    "\n",
    "This notebook generates topic-level analysis of CRINK (China, Russia, Iran, North Korea) voting alignment in UN General Assembly resolutions.\n",
    "\n",
    "## Workflow\n",
    "1. Load UN voting data\n",
    "2. Generate or load embeddings for resolution titles\n",
    "3. Run HDBSCAN clustering on embeddings\n",
    "4. Apply confirmed topic mappings (using fuzzy matching to reuse existing mappings)\n",
    "5. Assign noise resolutions to meta-topics (using undl_id-based mapping)\n",
    "6. Calculate CRINK alignment metrics by topic\n",
    "7. Generate summary tables for publication\n",
    "\n",
    "## Embedding Generation\n",
    "If embeddings don't exist or are mismatched, this notebook will generate new embeddings using the OpenAI API (requires `OPEN_AI_API` environment variable).\n",
    "\n",
    "## Reusing Existing Mappings\n",
    "- **Topic mappings**: Uses fuzzy matching to map new cluster labels to existing meta-topics\n",
    "- **Noise mappings**: Uses `undl_id` directly - works for any overlapping resolutions\n",
    "\n",
    "**Files required:**\n",
    "- `data/processed/UNGA_voting_records_filtered.csv`\n",
    "- `data/mappings/topic_mapping_confirmed_*.json`\n",
    "- `data/mappings/noise_mapping_confirmed_*.json`\n",
    "\n",
    "**Files generated (if needed):**\n",
    "- `data/mappings/UNGA_embeddings.npy`\n",
    "- `data/mappings/UNGA_embeddings_meta.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4068aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory: c:\\Users\\Lucian\\OneDrive - Tulane University\\01 IFSH\\Data Sciences try\\measuring-CRINK-alignment-UN\\data\\processed\n",
      "Mappings directory: c:\\Users\\Lucian\\OneDrive - Tulane University\\01 IFSH\\Data Sciences try\\measuring-CRINK-alignment-UN\\data\\mappings\n",
      "Results directory: c:\\Users\\Lucian\\OneDrive - Tulane University\\01 IFSH\\Data Sciences try\\measuring-CRINK-alignment-UN\\results\n",
      "\n",
      "Configuration loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports and Configuration\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import glob\n",
    "import re\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "from typing import List\n",
    "import hdbscan\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "# ================================================================\n",
    "# CONFIGURATION\n",
    "# ================================================================\n",
    "\n",
    "# CRINK country definitions\n",
    "CRINK_COUNTRIES = {\n",
    "    'CHINA': 'CHN',\n",
    "    'RUSSIAN FEDERATION': 'RUS',\n",
    "    'IRAN (ISLAMIC REPUBLIC OF)': 'IRN',\n",
    "    \"DEMOCRATIC PEOPLE'S REPUBLIC OF KOREA\": 'PRK'\n",
    "}\n",
    "\n",
    "# HDBSCAN parameters\n",
    "HDBSCAN_MIN_CLUSTER_SIZE = 10\n",
    "HDBSCAN_MIN_SAMPLES = 1\n",
    "\n",
    "# OpenAI embedding model\n",
    "EMBEDDING_MODEL = \"text-embedding-3-large\"\n",
    "EMBEDDING_BATCH_SIZE = 128\n",
    "\n",
    "# Plot and output settings\n",
    "FIGURE_SIZE = (14, 5)\n",
    "DPI = 300\n",
    "\n",
    "# Set up paths\n",
    "notebook_dir = Path.cwd()\n",
    "repo_root = notebook_dir.parent\n",
    "data_dir = repo_root / 'data' / 'processed'\n",
    "mappings_dir = repo_root / 'data' / 'mappings'\n",
    "results_dir = repo_root / 'results'\n",
    "\n",
    "# Embedding file paths\n",
    "embeddings_file = 'UNGA_embeddings.npy'\n",
    "embeddings_meta_file = 'UNGA_embeddings_meta.json'\n",
    "embeddings_path = mappings_dir / embeddings_file\n",
    "meta_path = mappings_dir / embeddings_meta_file\n",
    "\n",
    "# Ensure directories exist\n",
    "results_dir.mkdir(parents=True, exist_ok=True)\n",
    "mappings_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Data directory: {data_dir}\")\n",
    "print(f\"Mappings directory: {mappings_dir}\")\n",
    "print(f\"Results directory: {results_dir}\")\n",
    "print(\"\\nConfiguration loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4193a365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions loaded\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Helper Functions\n",
    "\n",
    "def load_mapping_json(filepath):\n",
    "    \"\"\"Load mapping dictionary from JSON file.\"\"\"\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # Separate metadata from mappings\n",
    "    metadata = data.pop('_metadata', {})\n",
    "    return data, metadata\n",
    "\n",
    "\n",
    "def find_latest_mapping_file(mappings_dir, pattern):\n",
    "    \"\"\"Find the most recent mapping file matching a pattern.\"\"\"\n",
    "    matching_files = sorted(glob.glob(str(mappings_dir / pattern)))\n",
    "    if not matching_files:\n",
    "        return None\n",
    "    return matching_files[-1]  # Most recent by timestamp in filename\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Minimal text cleaning for embeddings.\"\"\"\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "def fuzzy_match_topic(new_label, existing_mappings, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Try to match a new topic label to existing mappings using word overlap.\n",
    "    Returns (meta_topic, confidence) or (None, 0) if no match.\n",
    "    \"\"\"\n",
    "    new_words = set(new_label.lower().split())\n",
    "    \n",
    "    best_match = None\n",
    "    best_score = 0\n",
    "    \n",
    "    for old_label, meta_topic in existing_mappings.items():\n",
    "        old_words = set(old_label.lower().split())\n",
    "        \n",
    "        # Jaccard similarity\n",
    "        if len(new_words | old_words) > 0:\n",
    "            score = len(new_words & old_words) / len(new_words | old_words)\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_match = meta_topic\n",
    "    \n",
    "    if best_score >= threshold:\n",
    "        return best_match, best_score\n",
    "    return None, 0\n",
    "\n",
    "\n",
    "print(\"Helper functions loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d02ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Loaded UNGA_voting_records_filtered.csv\n",
      "  Total rows: 893,587\n",
      "  Unique resolutions: 5,415\n",
      "  Year range: 1946-2024\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Load Voting Data\n",
    "\n",
    "csv_file = 'UNGA_voting_records_filtered.csv'\n",
    "dataset_type = 'all_resolutions'\n",
    "\n",
    "# Year filter for post-Cold War analysis\n",
    "START_YEAR = 1991\n",
    "\n",
    "csv_path = data_dir / csv_file\n",
    "\n",
    "if not csv_path.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Data file not found: {csv_path}\\n\"\n",
    "        f\"Please download from Harvard Dataverse and place in {data_dir}\"\n",
    "    )\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(csv_path, encoding='utf-8', low_memory=False)\n",
    "\n",
    "# Standardize country names\n",
    "if 'ms_name' in df.columns:\n",
    "    df['ms_name'] = df['ms_name'].replace({'USSR': 'RUSSIAN FEDERATION'})\n",
    "\n",
    "# Convert dates and extract year\n",
    "if 'date' in df.columns:\n",
    "    df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "    df['year'] = df['date'].dt.year\n",
    "\n",
    "# Filter to post-Cold War era (1991+)\n",
    "df = df[df['year'] >= START_YEAR].copy()\n",
    "print(f\"âœ“ Filtered to {START_YEAR}+ (post-Cold War era)\")\n",
    "\n",
    "# Create resolution-level dataframe\n",
    "resolution_df = df.drop_duplicates('undl_id')[['undl_id', 'title', 'date', 'year']].copy()\n",
    "resolution_df = resolution_df.reset_index(drop=True)\n",
    "resolution_df['text_clean'] = resolution_df['title'].apply(clean_text)\n",
    "\n",
    "print(f\"âœ“ Loaded {csv_file}\")\n",
    "print(f\"  Total rows: {len(df):,}\")\n",
    "print(f\"  Unique resolutions: {len(resolution_df):,}\")\n",
    "print(f\"  Year range: {resolution_df['year'].min()}-{resolution_df['year'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e9546a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing embeddings: (7812, 3072)\n",
      "  Model: text-embedding-3-large\n",
      "  Expected rows: 7812\n",
      "\n",
      "âš  Mismatch: embeddings have 7812 rows, data has 5415 resolutions\n",
      "\n",
      "ðŸ”„ Generating new embeddings for 5415 resolutions...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "OpenAI API key not found. Set OPEN_AI_API environment variable.\nExample: $env:OPEN_AI_API = 'your-api-key'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 62\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mðŸ”„ Generating new embeddings for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_resolutions\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m resolutions...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     61\u001b[0m texts \u001b[38;5;241m=\u001b[39m resolution_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext_clean\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m---> 62\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# Save embeddings\u001b[39;00m\n\u001b[0;32m     65\u001b[0m np\u001b[38;5;241m.\u001b[39msave(embeddings_path, embeddings)\n",
      "Cell \u001b[1;32mIn[19], line 18\u001b[0m, in \u001b[0;36mgenerate_embeddings\u001b[1;34m(texts)\u001b[0m\n\u001b[0;32m     16\u001b[0m api_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPEN_AI_API\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m api_key:\n\u001b[1;32m---> 18\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     19\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOpenAI API key not found. Set OPEN_AI_API environment variable.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     20\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExample: $env:OPEN_AI_API = \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myour-api-key\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     21\u001b[0m     )\n\u001b[0;32m     23\u001b[0m client \u001b[38;5;241m=\u001b[39m OpenAI(api_key\u001b[38;5;241m=\u001b[39mapi_key)\n\u001b[0;32m     24\u001b[0m all_embeddings \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mValueError\u001b[0m: OpenAI API key not found. Set OPEN_AI_API environment variable.\nExample: $env:OPEN_AI_API = 'your-api-key'"
     ]
    }
   ],
   "source": [
    "# Cell 4: Generate or Load Embeddings\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load .env file from repo root\n",
    "env_path = repo_root / '.env'\n",
    "if env_path.exists():\n",
    "    load_dotenv(env_path)\n",
    "    print(f\"âœ“ Loaded .env from {env_path}\")\n",
    "else:\n",
    "    print(f\"âš  No .env file found at {env_path}\")\n",
    "\n",
    "\n",
    "def get_embeddings_from_api(texts: List[str], client) -> np.ndarray:\n",
    "    \"\"\"Call OpenAI embeddings API for a list of texts.\"\"\"\n",
    "    response = client.embeddings.create(\n",
    "        model=EMBEDDING_MODEL,\n",
    "        input=texts\n",
    "    )\n",
    "    return np.array([item.embedding for item in response.data], dtype=\"float32\")\n",
    "\n",
    "\n",
    "def generate_embeddings(texts: List[str]) -> np.ndarray:\n",
    "    \"\"\"Generate embeddings using OpenAI API.\"\"\"\n",
    "    from openai import OpenAI\n",
    "    \n",
    "    api_key = os.getenv(\"OPEN_AI_API\")\n",
    "    if not api_key:\n",
    "        raise ValueError(\n",
    "            \"OpenAI API key not found.\\n\"\n",
    "            \"Either:\\n\"\n",
    "            \"  1. Create a .env file in repo root with: OPEN_AI_API=your-key\\n\"\n",
    "            \"  2. Or set environment variable: $env:OPEN_AI_API = 'your-key'\"\n",
    "        )\n",
    "    \n",
    "    client = OpenAI(api_key=api_key)\n",
    "    all_embeddings = []\n",
    "    n = len(texts)\n",
    "    \n",
    "    for start in range(0, n, EMBEDDING_BATCH_SIZE):\n",
    "        end = min(start + EMBEDDING_BATCH_SIZE, n)\n",
    "        batch = texts[start:end]\n",
    "        print(f\"  Embedding batch {start}-{end} of {n}...\")\n",
    "        batch_embeddings = get_embeddings_from_api(batch, client)\n",
    "        all_embeddings.append(batch_embeddings)\n",
    "    \n",
    "    return np.vstack(all_embeddings)\n",
    "\n",
    "\n",
    "# Check if embeddings exist and match resolution count\n",
    "need_regenerate = False\n",
    "n_resolutions = len(resolution_df)\n",
    "\n",
    "if embeddings_path.exists() and meta_path.exists():\n",
    "    # Load existing embeddings\n",
    "    embeddings = np.load(embeddings_path)\n",
    "    with open(meta_path, 'r') as f:\n",
    "        emb_meta = json.load(f)\n",
    "    \n",
    "    print(f\"Found existing embeddings: {embeddings.shape}\")\n",
    "    print(f\"  Model: {emb_meta.get('model', 'unknown')}\")\n",
    "    print(f\"  Expected rows: {emb_meta.get('n_rows', 'unknown')}\")\n",
    "    \n",
    "    # Check if it matches current data\n",
    "    if embeddings.shape[0] != n_resolutions:\n",
    "        print(f\"\\nâš  Mismatch: embeddings have {embeddings.shape[0]} rows, data has {n_resolutions} resolutions\")\n",
    "        need_regenerate = True\n",
    "else:\n",
    "    print(\"No existing embeddings found.\")\n",
    "    need_regenerate = True\n",
    "\n",
    "if need_regenerate:\n",
    "    print(f\"\\nðŸ”„ Generating new embeddings for {n_resolutions} resolutions...\")\n",
    "    texts = resolution_df['text_clean'].tolist()\n",
    "    embeddings = generate_embeddings(texts)\n",
    "    \n",
    "    # Save embeddings\n",
    "    np.save(embeddings_path, embeddings)\n",
    "    \n",
    "    # Save metadata\n",
    "    emb_meta = {\n",
    "        \"model\": EMBEDDING_MODEL,\n",
    "        \"n_rows\": n_resolutions,\n",
    "        \"text_column\": \"title\",\n",
    "        \"generated_at\": datetime.now().isoformat()\n",
    "    }\n",
    "    with open(meta_path, 'w') as f:\n",
    "        json.dump(emb_meta, f, indent=2)\n",
    "    \n",
    "    print(f\"\\nâœ“ Saved new embeddings: {embeddings.shape}\")\n",
    "    print(f\"  File: {embeddings_path.name}\")\n",
    "else:\n",
    "    print(\"\\nâœ“ Using existing embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1634a658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running HDBSCAN clustering on embeddings...\n",
      "\n",
      "âœ“ HDBSCAN clustering complete\n",
      "  Clusters found: 247\n",
      "  Noise points: 842 (15.5%)\n",
      "\n",
      "Cluster distribution:\n",
      "cluster\n",
      "-1      842\n",
      " 117     60\n",
      " 223     56\n",
      " 120     40\n",
      " 137     39\n",
      " 154     38\n",
      " 4       36\n",
      " 210     36\n",
      " 9       36\n",
      " 10      36\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Run HDBSCAN Clustering\n",
    "\n",
    "print(\"Running HDBSCAN clustering on embeddings...\")\n",
    "\n",
    "# Create and fit HDBSCAN with same parameters as original\n",
    "clusterer = hdbscan.HDBSCAN(\n",
    "    min_cluster_size=HDBSCAN_MIN_CLUSTER_SIZE,\n",
    "    min_samples=HDBSCAN_MIN_SAMPLES,\n",
    "    metric='euclidean',\n",
    "    cluster_selection_method='eom',\n",
    "    prediction_data=True\n",
    ")\n",
    "\n",
    "cluster_labels = clusterer.fit_predict(embeddings)\n",
    "\n",
    "# Attach to dataframe\n",
    "resolution_df['cluster'] = cluster_labels\n",
    "resolution_df['cluster_prob'] = clusterer.probabilities_\n",
    "\n",
    "n_clusters = len(set(cluster_labels) - {-1})\n",
    "n_noise = (cluster_labels == -1).sum()\n",
    "\n",
    "print(f\"\\nâœ“ HDBSCAN clustering complete\")\n",
    "print(f\"  Clusters found: {n_clusters}\")\n",
    "print(f\"  Noise points: {n_noise} ({100*n_noise/len(resolution_df):.1f}%)\")\n",
    "print(f\"\\nCluster distribution:\")\n",
    "print(resolution_df['cluster'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d469d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Generated topic labels for 248 clusters\n",
      "\n",
      "Sample labels:\n",
      "  Cluster  -1 ( 842 items): Noise / Unclustered\n",
      "  Cluster   0 (  16 items): Information Oceans Law Sea\n",
      "  Cluster   1 (  15 items): Weapons Palestinian United Nations\n",
      "  Cluster   2 (  20 items): International Implementation Declaration United\n",
      "  Cluster   3 (  16 items): Nuclear Rights Use Weapons\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Generate Cluster Topic Labels\n",
    "\n",
    "# For each cluster, create a simple label based on common words in titles\n",
    "# (This is a reproducible fallback; the confirmed mappings will override these)\n",
    "\n",
    "def get_cluster_label(cluster_id, df, text_col='title', max_examples=10):\n",
    "    \"\"\"Generate a simple label for a cluster based on common title words.\"\"\"\n",
    "    if cluster_id == -1:\n",
    "        return \"Noise / Unclustered\"\n",
    "    \n",
    "    cluster_texts = df[df['cluster'] == cluster_id][text_col].head(max_examples).tolist()\n",
    "    if not cluster_texts:\n",
    "        return f\"Cluster {cluster_id}\"\n",
    "    \n",
    "    # Simple word frequency approach\n",
    "    words = []\n",
    "    stop_words = {'the', 'of', 'and', 'to', 'in', 'a', 'for', 'on', 'by', 'with', 'its', 'an', 'as', 'at', 'from'}\n",
    "    for text in cluster_texts:\n",
    "        words.extend([w.lower() for w in str(text).split() if w.lower() not in stop_words and len(w) > 2])\n",
    "    \n",
    "    word_counts = Counter(words)\n",
    "    top_words = [w for w, c in word_counts.most_common(4)]\n",
    "    return ' '.join(top_words).title() if top_words else f\"Cluster {cluster_id}\"\n",
    "\n",
    "\n",
    "# Generate initial topic labels for all clusters\n",
    "cluster_ids = sorted(set(resolution_df['cluster']))\n",
    "cluster_topic_labels = {}\n",
    "\n",
    "for cl in cluster_ids:\n",
    "    cluster_topic_labels[cl] = get_cluster_label(cl, resolution_df)\n",
    "\n",
    "# Apply labels to dataframe\n",
    "resolution_df['topic_label'] = resolution_df['cluster'].map(cluster_topic_labels)\n",
    "\n",
    "print(f\"âœ“ Generated topic labels for {len(cluster_topic_labels)} clusters\")\n",
    "print(f\"\\nSample labels:\")\n",
    "for cl in list(cluster_ids)[:5]:\n",
    "    count = (resolution_df['cluster'] == cl).sum()\n",
    "    print(f\"  Cluster {cl:3d} ({count:4d} items): {cluster_topic_labels[cl]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e324056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Loaded topic mapping: topic_mapping_confirmed_all_resolutions_20251208_180017.json\n",
      "  Mappings: 86\n",
      "  Timestamp: 20251208_175334\n",
      "\n",
      "9 Meta-Topics:\n",
      "   1. Development (10 original topics)\n",
      "   2. Disarmament (32 original topics)\n",
      "   3. Displacement (4 original topics)\n",
      "   4. Economic Sanctions (3 original topics)\n",
      "   5. Human Rights (14 original topics)\n",
      "   6. Human Rights in CRINK (4 original topics)\n",
      "   7. International Cooperation (3 original topics)\n",
      "   8. International Law (3 original topics)\n",
      "   9. Israel/Palestine Conflict (13 original topics)\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Load Confirmed Topic Mapping and Apply with Fuzzy Matching\n",
    "\n",
    "# Find the most recent confirmed topic mapping file\n",
    "topic_mapping_pattern = f\"topic_mapping_confirmed_{dataset_type}_*.json\"\n",
    "topic_mapping_file = find_latest_mapping_file(mappings_dir, topic_mapping_pattern)\n",
    "\n",
    "if topic_mapping_file is None:\n",
    "    raise FileNotFoundError(\n",
    "        f\"No topic mapping file found matching: {topic_mapping_pattern}\\n\"\n",
    "        f\"Expected in: {mappings_dir}\"\n",
    "    )\n",
    "\n",
    "topic_to_meta, topic_meta = load_mapping_json(topic_mapping_file)\n",
    "\n",
    "print(f\"âœ“ Loaded topic mapping: {Path(topic_mapping_file).name}\")\n",
    "print(f\"  Original mappings: {len(topic_to_meta)}\")\n",
    "\n",
    "# Get available meta-topics\n",
    "available_meta_topics = sorted(set(topic_to_meta.values()))\n",
    "print(f\"  Meta-topics: {len(available_meta_topics)}\")\n",
    "\n",
    "# Map new cluster labels to meta-topics using fuzzy matching\n",
    "new_topic_to_meta = {}\n",
    "unmatched_topics = []\n",
    "match_stats = {'exact': 0, 'fuzzy': 0, 'unmatched': 0}\n",
    "\n",
    "for cluster_id, new_label in cluster_topic_labels.items():\n",
    "    if cluster_id == -1:\n",
    "        continue  # Skip noise cluster\n",
    "    \n",
    "    # Try exact match first\n",
    "    if new_label in topic_to_meta:\n",
    "        new_topic_to_meta[new_label] = topic_to_meta[new_label]\n",
    "        match_stats['exact'] += 1\n",
    "    else:\n",
    "        # Try fuzzy match\n",
    "        meta_topic, confidence = fuzzy_match_topic(new_label, topic_to_meta, threshold=0.3)\n",
    "        if meta_topic:\n",
    "            new_topic_to_meta[new_label] = meta_topic\n",
    "            match_stats['fuzzy'] += 1\n",
    "        else:\n",
    "            # No match - assign to Miscellaneous\n",
    "            new_topic_to_meta[new_label] = 'Miscellaneous'\n",
    "            unmatched_topics.append(new_label)\n",
    "            match_stats['unmatched'] += 1\n",
    "\n",
    "print(f\"\\nMapping results:\")\n",
    "print(f\"  Exact matches: {match_stats['exact']}\")\n",
    "print(f\"  Fuzzy matches: {match_stats['fuzzy']}\")\n",
    "print(f\"  Unmatched (â†’ Miscellaneous): {match_stats['unmatched']}\")\n",
    "\n",
    "if unmatched_topics:\n",
    "    print(f\"\\nUnmatched topics (assigned to Miscellaneous):\")\n",
    "    for t in unmatched_topics[:10]:\n",
    "        print(f\"  - {t}\")\n",
    "    if len(unmatched_topics) > 10:\n",
    "        print(f\"  ... and {len(unmatched_topics) - 10} more\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d985db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Loaded noise mapping: noise_mapping_confirmed_all_resolutions_20251208_180624.json\n",
      "  Noise resolutions mapped: 0\n",
      "  Timestamp: 20251208_180547\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Load Confirmed Noise Mapping (by undl_id)\n",
    "\n",
    "# Find the most recent confirmed noise mapping file\n",
    "noise_mapping_pattern = f\"noise_mapping_confirmed_{dataset_type}_*.json\"\n",
    "noise_mapping_file = find_latest_mapping_file(mappings_dir, noise_mapping_pattern)\n",
    "\n",
    "if noise_mapping_file is None:\n",
    "    print(f\"âš  No noise mapping file found. Noise items will be labeled 'Miscellaneous'.\")\n",
    "    noise_to_meta = {}\n",
    "else:\n",
    "    noise_mapping_raw, noise_meta = load_mapping_json(noise_mapping_file)\n",
    "    \n",
    "    # Handle both formats:\n",
    "    # Format 1: {\"undl_id\": \"meta_topic\", ...}\n",
    "    # Format 2: {\"0\": {\"id\": \"undl_id\", \"assigned_topic\": \"meta_topic\"}, ...}\n",
    "    noise_to_meta = {}\n",
    "    for key, value in noise_mapping_raw.items():\n",
    "        if isinstance(value, dict) and 'id' in value and 'assigned_topic' in value:\n",
    "            # Format 2\n",
    "            noise_to_meta[str(value['id'])] = value['assigned_topic']\n",
    "        elif isinstance(value, str):\n",
    "            # Format 1\n",
    "            noise_to_meta[str(key)] = value\n",
    "    \n",
    "    print(f\"âœ“ Loaded noise mapping: {Path(noise_mapping_file).name}\")\n",
    "    print(f\"  Noise resolutions mapped: {len(noise_to_meta)}\")\n",
    "\n",
    "# Count how many noise points we can map\n",
    "noise_resolutions = resolution_df[resolution_df['cluster'] == -1]['undl_id'].astype(str).tolist()\n",
    "mappable = sum(1 for uid in noise_resolutions if uid in noise_to_meta)\n",
    "print(f\"\\n  Current noise points: {len(noise_resolutions)}\")\n",
    "print(f\"  Mappable from existing: {mappable} ({100*mappable/max(1,len(noise_resolutions)):.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898979b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying topic and noise mappings...\n",
      "\n",
      "âœ“ Applied mappings to 5415 resolutions\n",
      "  Unique meta-topics: 1\n",
      "\n",
      "Meta-topic distribution:\n",
      "meta_topic_label\n",
      "Uncategorized    5415\n",
      "Name: count, dtype: int64\n",
      "\n",
      "âš  Uncategorized resolutions: 5415 (100.0%)\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Apply Mappings to Create Meta-Topic Column\n",
    "\n",
    "print(\"Applying topic and noise mappings...\")\n",
    "\n",
    "# Initialize meta_topic_label column\n",
    "resolution_df['meta_topic_label'] = None\n",
    "\n",
    "# Step 1: Apply topic-to-meta mapping for clustered (non-noise) rows\n",
    "mapped_from_topic = 0\n",
    "for new_label, meta_topic in new_topic_to_meta.items():\n",
    "    mask = resolution_df['topic_label'] == new_label\n",
    "    resolution_df.loc[mask, 'meta_topic_label'] = meta_topic\n",
    "    mapped_from_topic += mask.sum()\n",
    "\n",
    "print(f\"  Mapped from topic labels: {mapped_from_topic}\")\n",
    "\n",
    "# Step 2: Apply noise-to-meta mapping for noise rows (by undl_id)\n",
    "mapped_from_noise = 0\n",
    "if noise_to_meta:\n",
    "    for idx, row in resolution_df[resolution_df['cluster'] == -1].iterrows():\n",
    "        undl_id_str = str(row['undl_id'])\n",
    "        if undl_id_str in noise_to_meta:\n",
    "            resolution_df.loc[idx, 'meta_topic_label'] = noise_to_meta[undl_id_str]\n",
    "            mapped_from_noise += 1\n",
    "\n",
    "print(f\"  Mapped from noise (by undl_id): {mapped_from_noise}\")\n",
    "\n",
    "# Step 3: Fill remaining nulls with 'Miscellaneous'\n",
    "unmapped = resolution_df['meta_topic_label'].isna().sum()\n",
    "resolution_df['meta_topic_label'] = resolution_df['meta_topic_label'].fillna('Miscellaneous')\n",
    "print(f\"  Assigned to Miscellaneous: {unmapped}\")\n",
    "\n",
    "# Create numeric meta_topic_id\n",
    "unique_meta_topics = sorted(resolution_df['meta_topic_label'].unique())\n",
    "meta_topic_id_map = {mt: i for i, mt in enumerate(unique_meta_topics)}\n",
    "resolution_df['meta_topic_id'] = resolution_df['meta_topic_label'].map(meta_topic_id_map)\n",
    "\n",
    "print(f\"\\nâœ“ Applied mappings to {len(resolution_df)} resolutions\")\n",
    "print(f\"  Unique meta-topics: {len(unique_meta_topics)}\")\n",
    "print(f\"\\nMeta-topic distribution:\")\n",
    "print(resolution_df['meta_topic_label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c779cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CRINK voting alignment...\n",
      "\n",
      "âœ“ Calculated alignment for 5415 resolutions\n",
      "\n",
      "Alignment summary:\n",
      "  4-way alignment (all 4 CRINK): 1373\n",
      "  3-way alignment (3 of 4 CRINK): 1658\n",
      "  2-way alignment (2 of 4 CRINK): 1525\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Calculate CRINK Voting Alignment by Resolution\n",
    "\n",
    "print(\"Calculating CRINK voting alignment...\")\n",
    "\n",
    "# Get CRINK country votes for each resolution\n",
    "crink_names = list(CRINK_COUNTRIES.keys())\n",
    "crink_codes = list(CRINK_COUNTRIES.values())\n",
    "\n",
    "# Pivot to get one column per CRINK country\n",
    "crink_votes_df = df[df['ms_name'].isin(crink_names)].pivot_table(\n",
    "    index='undl_id',\n",
    "    columns='ms_name',\n",
    "    values='ms_vote',\n",
    "    aggfunc='first'\n",
    ").reset_index()\n",
    "\n",
    "# Merge with resolution_df\n",
    "resolution_df = resolution_df.merge(crink_votes_df, on='undl_id', how='left')\n",
    "\n",
    "# Calculate alignment metrics\n",
    "def calculate_crink_alignment(row):\n",
    "    \"\"\"Calculate how many CRINK countries voted together.\"\"\"\n",
    "    votes = [row.get(c) for c in crink_names if c in row.index and pd.notna(row.get(c))]\n",
    "    \n",
    "    if len(votes) < 2:\n",
    "        return pd.Series({\n",
    "            'crink_votes_available': len(votes),\n",
    "            'max_agreement_count': 0,\n",
    "            'four_vote_alignment': 0,\n",
    "            'three_vote_alignment': 0,\n",
    "            'two_vote_alignment': 0,\n",
    "            'crink_group_vote': None\n",
    "        })\n",
    "    \n",
    "    vote_counts = Counter(votes)\n",
    "    most_common_vote, max_count = vote_counts.most_common(1)[0]\n",
    "    \n",
    "    return pd.Series({\n",
    "        'crink_votes_available': len(votes),\n",
    "        'max_agreement_count': max_count,\n",
    "        'four_vote_alignment': 1 if max_count == 4 else 0,\n",
    "        'three_vote_alignment': 1 if max_count == 3 else 0,\n",
    "        'two_vote_alignment': 1 if max_count == 2 else 0,\n",
    "        'crink_group_vote': most_common_vote\n",
    "    })\n",
    "\n",
    "alignment_results = resolution_df.apply(calculate_crink_alignment, axis=1)\n",
    "resolution_df = pd.concat([resolution_df, alignment_results], axis=1)\n",
    "\n",
    "print(f\"\\nâœ“ Calculated alignment for {len(resolution_df)} resolutions\")\n",
    "print(f\"\\nAlignment summary:\")\n",
    "print(f\"  4-way alignment (all 4 CRINK): {resolution_df['four_vote_alignment'].sum()}\")\n",
    "print(f\"  3-way alignment (3 of 4 CRINK): {resolution_df['three_vote_alignment'].sum()}\")\n",
    "print(f\"  2-way alignment (2 of 4 CRINK): {resolution_df['two_vote_alignment'].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb28b7b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Added US vote and UN majority alignment\n",
      "  CRINK against US: 3884 resolutions\n",
      "  CRINK with UN majority: 4058 resolutions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lucian\\AppData\\Local\\Temp\\ipykernel_18876\\3287003252.py:25: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  majority_votes = df.groupby('undl_id').apply(get_majority_vote).reset_index()\n"
     ]
    }
   ],
   "source": [
    "# Cell 11: Add US Vote and UN Majority Alignment\n",
    "\n",
    "# Get US votes\n",
    "us_votes = df[df['ms_name'] == 'UNITED STATES'][['undl_id', 'ms_vote']].rename(\n",
    "    columns={'ms_vote': 'us_vote'}\n",
    ").drop_duplicates('undl_id')\n",
    "\n",
    "resolution_df = resolution_df.merge(us_votes, on='undl_id', how='left')\n",
    "\n",
    "# Calculate CRINK against US\n",
    "resolution_df['crink_against_us'] = (\n",
    "    (resolution_df['crink_group_vote'] != resolution_df['us_vote']) &\n",
    "    resolution_df['crink_group_vote'].notna() &\n",
    "    resolution_df['us_vote'].notna() &\n",
    "    (resolution_df['max_agreement_count'] >= 2)\n",
    ").astype(int)\n",
    "\n",
    "# Calculate UN majority vote per resolution\n",
    "def get_majority_vote(group):\n",
    "    votes = group['ms_vote'].dropna()\n",
    "    if len(votes) == 0:\n",
    "        return None\n",
    "    return votes.mode().iloc[0] if len(votes.mode()) > 0 else None\n",
    "\n",
    "majority_votes = df.groupby('undl_id').apply(get_majority_vote).reset_index()\n",
    "majority_votes.columns = ['undl_id', 'un_majority_vote']\n",
    "\n",
    "resolution_df = resolution_df.merge(majority_votes, on='undl_id', how='left')\n",
    "\n",
    "# Calculate CRINK with majority\n",
    "resolution_df['crink_with_majority'] = (\n",
    "    (resolution_df['crink_group_vote'] == resolution_df['un_majority_vote']) &\n",
    "    resolution_df['crink_group_vote'].notna() &\n",
    "    (resolution_df['max_agreement_count'] >= 2)\n",
    ").astype(int)\n",
    "\n",
    "print(f\"âœ“ Added US vote and UN majority alignment\")\n",
    "print(f\"  CRINK against US: {resolution_df['crink_against_us'].sum()} resolutions\")\n",
    "print(f\"  CRINK with UN majority: {resolution_df['crink_with_majority'].sum()} resolutions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d3b41d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating topic alignment summary table...\n",
      "\n",
      "====================================================================================================\n",
      "CRINK VOTING ALIGNMENT BY META-TOPIC (UNGA)\n",
      "Total resolutions: 5415\n",
      "Sorted by 4-way alignment (all CRINK countries vote together)\n",
      "====================================================================================================\n",
      "\n",
      " Rank    Meta-Topic    N  4-Way %  3-Way %  2-Way %  vs US %  w/ Majority %\n",
      "    1 Uncategorized 5415     25.4     30.6     28.2     71.7           74.9\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Column definitions:\n",
      "  4-Way %: Share of resolutions where all 4 CRINK vote the same\n",
      "  3-Way %: Share where 3 of 4 CRINK vote the same\n",
      "  2-Way %: Share where 2 of 4 CRINK vote the same\n",
      "  vs US %: Share where CRINK majority voted against US\n",
      "  w/ Majority %: Share where CRINK majority aligned with UN majority\n"
     ]
    }
   ],
   "source": [
    "# Cell 12: Generate Topic Alignment Summary Table\n",
    "\n",
    "print(\"Generating topic alignment summary table...\\n\")\n",
    "\n",
    "# Aggregate by meta-topic\n",
    "topic_summary = resolution_df.groupby('meta_topic_label').agg(\n",
    "    n_resolutions=('undl_id', 'count'),\n",
    "    four_way_count=('four_vote_alignment', 'sum'),\n",
    "    three_way_count=('three_vote_alignment', 'sum'),\n",
    "    two_way_count=('two_vote_alignment', 'sum'),\n",
    "    against_us_count=('crink_against_us', 'sum'),\n",
    "    with_majority_count=('crink_with_majority', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# Calculate percentages\n",
    "topic_summary['four_way_pct'] = (100 * topic_summary['four_way_count'] / topic_summary['n_resolutions']).round(1)\n",
    "topic_summary['three_way_pct'] = (100 * topic_summary['three_way_count'] / topic_summary['n_resolutions']).round(1)\n",
    "topic_summary['two_way_pct'] = (100 * topic_summary['two_way_count'] / topic_summary['n_resolutions']).round(1)\n",
    "topic_summary['against_us_pct'] = (100 * topic_summary['against_us_count'] / topic_summary['n_resolutions']).round(1)\n",
    "topic_summary['with_majority_pct'] = (100 * topic_summary['with_majority_count'] / topic_summary['n_resolutions']).round(1)\n",
    "\n",
    "# Sort by 4-way alignment\n",
    "topic_summary = topic_summary.sort_values('four_way_pct', ascending=False).reset_index(drop=True)\n",
    "topic_summary['rank'] = range(1, len(topic_summary) + 1)\n",
    "\n",
    "# Select display columns\n",
    "display_cols = [\n",
    "    'rank', 'meta_topic_label', 'n_resolutions',\n",
    "    'four_way_pct', 'three_way_pct', 'two_way_pct',\n",
    "    'against_us_pct', 'with_majority_pct'\n",
    "]\n",
    "\n",
    "display_df = topic_summary[display_cols].copy()\n",
    "display_df.columns = [\n",
    "    'Rank', 'Meta-Topic', 'N',\n",
    "    '4-Way %', '3-Way %', '2-Way %',\n",
    "    'vs US %', 'w/ Majority %'\n",
    "]\n",
    "\n",
    "print(\"=\" * 100)\n",
    "print(\"CRINK VOTING ALIGNMENT BY META-TOPIC (UNGA)\")\n",
    "print(f\"Total resolutions: {len(resolution_df)}\")\n",
    "print(\"Sorted by 4-way alignment (all CRINK countries vote together)\")\n",
    "print(\"=\" * 100)\n",
    "print()\n",
    "print(display_df.to_string(index=False))\n",
    "print()\n",
    "print(\"=\" * 100)\n",
    "print(\"\\nColumn definitions:\")\n",
    "print(\"  4-Way %: Share of resolutions where all 4 CRINK vote the same\")\n",
    "print(\"  3-Way %: Share where 3 of 4 CRINK vote the same\")\n",
    "print(\"  2-Way %: Share where 2 of 4 CRINK vote the same\")\n",
    "print(\"  vs US %: Share where CRINK majority voted against US\")\n",
    "print(\"  w/ Majority %: Share where CRINK majority aligned with UN majority\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb40583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Saved: Table2_Topic_Distribution_CRINK_Fully_Aligned_UNGA_20260109.csv\n",
      "âœ“ Saved: resolutions_with_metatopics_UNGA_20260109.csv\n",
      "âœ“ Saved: Table2_Topic_Distribution_CRINK_Fully_Aligned_UNGA.tex\n",
      "\n",
      "============================================================\n",
      "ALL RESULTS SAVED\n",
      "============================================================\n",
      "\n",
      "Output files in: c:\\Users\\Lucian\\OneDrive - Tulane University\\01 IFSH\\Data Sciences try\\measuring-CRINK-alignment-UN\\results\n",
      "\n",
      "Table 2: Topic Distribution of Resolutions where CRINK States Fully Aligned in the UNGA Plenary, 1991-2024\n"
     ]
    }
   ],
   "source": [
    "# Cell 13: Save Results\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d')\n",
    "\n",
    "# Table naming for publication\n",
    "TABLE_NAME = \"Table2_Topic_Distribution_CRINK_Fully_Aligned\"\n",
    "TABLE_CAPTION = \"Topic Distribution of Resolutions where CRINK States Fully Aligned in the UNGA Plenary, 1991-2024\"\n",
    "\n",
    "# Save summary table as CSV\n",
    "summary_csv = results_dir / f'{TABLE_NAME}_UNGA_{timestamp}.csv'\n",
    "topic_summary.to_csv(summary_csv, index=False)\n",
    "print(f\"âœ“ Saved: {summary_csv.name}\")\n",
    "\n",
    "# Save full resolution data with meta-topics\n",
    "full_csv = results_dir / f'resolutions_with_metatopics_UNGA_{timestamp}.csv'\n",
    "export_cols = ['undl_id', 'title', 'date', 'year', 'cluster', 'topic_label', \n",
    "               'meta_topic_label', 'meta_topic_id', 'crink_group_vote',\n",
    "               'max_agreement_count', 'four_vote_alignment', 'three_vote_alignment',\n",
    "               'two_vote_alignment', 'crink_against_us', 'crink_with_majority']\n",
    "export_cols = [c for c in export_cols if c in resolution_df.columns]\n",
    "resolution_df[export_cols].to_csv(full_csv, index=False)\n",
    "print(f\"âœ“ Saved: {full_csv.name}\")\n",
    "\n",
    "# Generate LaTeX table\n",
    "def generate_latex_table(df_table, caption, label):\n",
    "    \"\"\"Generate LaTeX table with academic formatting.\"\"\"\n",
    "    df_clean = df_table.drop(columns=['Rank']) if 'Rank' in df_table.columns else df_table.copy()\n",
    "    \n",
    "    # Build LaTeX\n",
    "    n_cols = len(df_clean.columns)\n",
    "    col_spec = 'l' + 'r' * (n_cols - 1)\n",
    "    \n",
    "    latex = f\"\"\"\\\\begin{{table}}[htbp]\n",
    "\\\\centering\n",
    "\\\\footnotesize\n",
    "\\\\begin{{tabular}}{{{col_spec}}}\n",
    "\\\\hline\n",
    "\"\"\"\n",
    "    \n",
    "    # Header\n",
    "    headers = [c.replace('%', '\\\\%').replace('_', ' ') for c in df_clean.columns]\n",
    "    latex += ' & '.join([f'\\\\textbf{{{h}}}' for h in headers]) + ' \\\\\\\\\\n'\n",
    "    latex += '\\\\hline\\n'\n",
    "    \n",
    "    # Data rows\n",
    "    for _, row in df_clean.iterrows():\n",
    "        values = []\n",
    "        for col in df_clean.columns:\n",
    "            val = row[col]\n",
    "            if isinstance(val, float):\n",
    "                values.append(f'{val:.1f}')\n",
    "            else:\n",
    "                values.append(str(val).replace('&', '\\\\&').replace('%', '\\\\%'))\n",
    "        latex += ' & '.join(values) + ' \\\\\\\\\\n'\n",
    "    \n",
    "    latex += f\"\"\"\\\\hline\n",
    "\\\\end{{tabular}}\n",
    "\\\\caption{{{caption}}}\n",
    "\\\\label{{{label}}}\n",
    "\\\\end{{table}}\n",
    "\"\"\"\n",
    "    return latex\n",
    "\n",
    "latex_table = generate_latex_table(display_df, TABLE_CAPTION, \"tab:table2_topic_distribution\")\n",
    "\n",
    "latex_file = results_dir / f'{TABLE_NAME}_UNGA.tex'\n",
    "with open(latex_file, 'w', encoding='utf-8') as f:\n",
    "    f.write(latex_table)\n",
    "print(f\"âœ“ Saved: {latex_file.name}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"ALL RESULTS SAVED\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"\\nOutput files in: {results_dir}\")\n",
    "print(f\"\\nTable 2: {TABLE_CAPTION}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424b3ac2",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook has:\n",
    "1. Loaded UN voting data (5,415 unique resolutions, 1946-2024)\n",
    "2. Generated or loaded embeddings using OpenAI's `text-embedding-3-large` model\n",
    "3. Run HDBSCAN clustering to assign resolutions to topic clusters\n",
    "4. Applied confirmed topic mappings using fuzzy matching to reuse existing meta-topic assignments\n",
    "5. Assigned noise resolutions to meta-topics using undl_id-based mapping\n",
    "6. Calculated CRINK voting alignment metrics (4-way, 3-way, 2-way, vs US, with UN majority)\n",
    "7. Generated summary tables for publication\n",
    "\n",
    "### Mapping Reuse Strategy\n",
    "- **Topic mappings**: Fuzzy word-overlap matching to map new cluster labels â†’ existing meta-topics\n",
    "- **Noise mappings**: Direct undl_id lookup (works for overlapping resolutions)\n",
    "- **Unmatched items**: Assigned to \"Miscellaneous\" category\n",
    "\n",
    "### Reproducibility Notes\n",
    "- Embeddings are saved to `data/mappings/UNGA_embeddings.npy`\n",
    "- HDBSCAN parameters: `min_cluster_size=10`, `min_samples=1`\n",
    "- Requires `OPEN_AI_API` environment variable for embedding generation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Webscraping",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
