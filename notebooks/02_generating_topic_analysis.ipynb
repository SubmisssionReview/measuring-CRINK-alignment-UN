{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c755300",
   "metadata": {},
   "source": [
    "# Topic Analysis of CRINK Voting Patterns\n",
    "\n",
    "This notebook generates topic-level analysis of CRINK (China, Russia, Iran, North Korea) voting alignment in UN General Assembly resolutions.\n",
    "\n",
    "## Workflow\n",
    "1. Load UN voting data\n",
    "2. Generate or load embeddings for resolution titles\n",
    "3. Run HDBSCAN clustering on embeddings\n",
    "4. Apply confirmed topic mappings (using fuzzy matching to reuse existing mappings)\n",
    "5. Assign noise resolutions to meta-topics (using undl_id-based mapping)\n",
    "6. Calculate CRINK alignment metrics by topic\n",
    "7. Generate summary tables for publication\n",
    "\n",
    "## Embedding Generation\n",
    "If embeddings don't exist or are mismatched, this notebook will generate new embeddings using the OpenAI API (requires `OPEN_AI_API` environment variable).\n",
    "\n",
    "## Reusing Existing Mappings\n",
    "- **Topic mappings**: Uses fuzzy matching to map new cluster labels to existing meta-topics\n",
    "- **Noise mappings**: Uses `undl_id` directly - works for any overlapping resolutions\n",
    "\n",
    "**Files required:**\n",
    "- `data/processed/UNGA_voting_records_filtered.csv`\n",
    "- `data/mappings/topic_mapping_confirmed_*.json`\n",
    "- `data/mappings/noise_mapping_confirmed_*.json`\n",
    "\n",
    "**Files generated (if needed):**\n",
    "- `data/mappings/UNGA_embeddings.npy`\n",
    "- `data/mappings/UNGA_embeddings_meta.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4068aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory: c:\\Users\\Lucian\\OneDrive - Tulane University\\01 IFSH\\Data Sciences try\\measuring-CRINK-alignment-UN\\data\\processed\n",
      "Mappings directory: c:\\Users\\Lucian\\OneDrive - Tulane University\\01 IFSH\\Data Sciences try\\measuring-CRINK-alignment-UN\\data\\mappings\n",
      "Results directory: c:\\Users\\Lucian\\OneDrive - Tulane University\\01 IFSH\\Data Sciences try\\measuring-CRINK-alignment-UN\\results\n",
      "\n",
      "Configuration loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports and Configuration\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import glob\n",
    "import re\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "from typing import List\n",
    "import hdbscan\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "# ================================================================\n",
    "# CONFIGURATION\n",
    "# ================================================================\n",
    "\n",
    "# CRINK country definitions\n",
    "CRINK_COUNTRIES = {\n",
    "    'CHINA': 'CHN',\n",
    "    'RUSSIAN FEDERATION': 'RUS',\n",
    "    'IRAN (ISLAMIC REPUBLIC OF)': 'IRN',\n",
    "    \"DEMOCRATIC PEOPLE'S REPUBLIC OF KOREA\": 'PRK'\n",
    "}\n",
    "\n",
    "# HDBSCAN parameters\n",
    "HDBSCAN_MIN_CLUSTER_SIZE = 10\n",
    "HDBSCAN_MIN_SAMPLES = 1\n",
    "\n",
    "# OpenAI embedding model\n",
    "EMBEDDING_MODEL = \"text-embedding-3-large\"\n",
    "EMBEDDING_BATCH_SIZE = 128\n",
    "\n",
    "# Plot and output settings\n",
    "FIGURE_SIZE = (14, 5)\n",
    "DPI = 300\n",
    "\n",
    "# Set up paths\n",
    "notebook_dir = Path.cwd()\n",
    "repo_root = notebook_dir.parent\n",
    "data_dir = repo_root / 'data' / 'processed'\n",
    "mappings_dir = repo_root / 'data' / 'mappings'\n",
    "results_dir = repo_root / 'results'\n",
    "\n",
    "# Embedding file paths\n",
    "embeddings_file = 'UNGA_embeddings.npy'\n",
    "embeddings_meta_file = 'UNGA_embeddings_meta.json'\n",
    "embeddings_path = mappings_dir / embeddings_file\n",
    "meta_path = mappings_dir / embeddings_meta_file\n",
    "\n",
    "# Ensure directories exist\n",
    "results_dir.mkdir(parents=True, exist_ok=True)\n",
    "mappings_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Data directory: {data_dir}\")\n",
    "print(f\"Mappings directory: {mappings_dir}\")\n",
    "print(f\"Results directory: {results_dir}\")\n",
    "print(\"\\nConfiguration loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4193a365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions loaded\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Helper Functions\n",
    "\n",
    "def load_mapping_json(filepath):\n",
    "    \"\"\"Load mapping dictionary from JSON file.\"\"\"\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # Separate metadata from mappings\n",
    "    metadata = data.pop('_metadata', {})\n",
    "    return data, metadata\n",
    "\n",
    "\n",
    "def find_latest_mapping_file(mappings_dir, pattern):\n",
    "    \"\"\"Find the most recent mapping file matching a pattern.\"\"\"\n",
    "    matching_files = sorted(glob.glob(str(mappings_dir / pattern)))\n",
    "    if not matching_files:\n",
    "        return None\n",
    "    return matching_files[-1]  # Most recent by timestamp in filename\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Minimal text cleaning for embeddings.\"\"\"\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "def fuzzy_match_topic(new_label, existing_mappings, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Try to match a new topic label to existing mappings using word overlap.\n",
    "    Returns (meta_topic, confidence) or (None, 0) if no match.\n",
    "    \"\"\"\n",
    "    new_words = set(new_label.lower().split())\n",
    "    \n",
    "    best_match = None\n",
    "    best_score = 0\n",
    "    \n",
    "    for old_label, meta_topic in existing_mappings.items():\n",
    "        old_words = set(old_label.lower().split())\n",
    "        \n",
    "        # Jaccard similarity\n",
    "        if len(new_words | old_words) > 0:\n",
    "            score = len(new_words & old_words) / len(new_words | old_words)\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_match = meta_topic\n",
    "    \n",
    "    if best_score >= threshold:\n",
    "        return best_match, best_score\n",
    "    return None, 0\n",
    "\n",
    "\n",
    "print(\"Helper functions loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34d02ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Filtered to 1991+ (post-Cold War era)\n",
      "âœ“ Loaded UNGA_voting_records_filtered.csv\n",
      "  Total rows: 492,762\n",
      "  Unique resolutions: 2,597\n",
      "  Year range: 1991-2024\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Load Voting Data\n",
    "\n",
    "csv_file = 'UNGA_voting_records_filtered.csv'\n",
    "dataset_type = 'all_resolutions'\n",
    "\n",
    "# Year filter for post-Cold War analysis\n",
    "START_YEAR = 1991\n",
    "\n",
    "csv_path = data_dir / csv_file\n",
    "\n",
    "if not csv_path.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Data file not found: {csv_path}\\n\"\n",
    "        f\"Please download from Harvard Dataverse and place in {data_dir}\"\n",
    "    )\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(csv_path, encoding='utf-8', low_memory=False)\n",
    "\n",
    "# Standardize country names\n",
    "if 'ms_name' in df.columns:\n",
    "    df['ms_name'] = df['ms_name'].replace({'USSR': 'RUSSIAN FEDERATION'})\n",
    "\n",
    "# Convert dates and extract year\n",
    "if 'date' in df.columns:\n",
    "    df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "    df['year'] = df['date'].dt.year\n",
    "\n",
    "# Filter to post-Cold War era (1991+)\n",
    "df = df[df['year'] >= START_YEAR].copy()\n",
    "print(f\"âœ“ Filtered to {START_YEAR}+ (post-Cold War era)\")\n",
    "\n",
    "# Create resolution-level dataframe\n",
    "resolution_df = df.drop_duplicates('undl_id')[['undl_id', 'title', 'date', 'year']].copy()\n",
    "resolution_df = resolution_df.reset_index(drop=True)\n",
    "resolution_df['text_clean'] = resolution_df['title'].apply(clean_text)\n",
    "\n",
    "print(f\"âœ“ Loaded {csv_file}\")\n",
    "print(f\"  Total rows: {len(df):,}\")\n",
    "print(f\"  Unique resolutions: {len(resolution_df):,}\")\n",
    "print(f\"  Year range: {resolution_df['year'].min()}-{resolution_df['year'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2e9546a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Loaded .env from c:\\Users\\Lucian\\OneDrive - Tulane University\\01 IFSH\\Data Sciences try\\measuring-CRINK-alignment-UN\\.env\n",
      "Found existing embeddings: (7812, 3072)\n",
      "  Model: text-embedding-3-large\n",
      "  Expected rows: 7812\n",
      "\n",
      "âš  Mismatch: embeddings have 7812 rows, data has 2597 resolutions\n",
      "\n",
      "ðŸ”„ Generating new embeddings for 2597 resolutions...\n",
      "  Embedding batch 0-128 of 2597...\n",
      "  Embedding batch 128-256 of 2597...\n",
      "  Embedding batch 256-384 of 2597...\n",
      "  Embedding batch 384-512 of 2597...\n",
      "  Embedding batch 512-640 of 2597...\n",
      "  Embedding batch 640-768 of 2597...\n",
      "  Embedding batch 768-896 of 2597...\n",
      "  Embedding batch 896-1024 of 2597...\n",
      "  Embedding batch 1024-1152 of 2597...\n",
      "  Embedding batch 1152-1280 of 2597...\n",
      "  Embedding batch 1280-1408 of 2597...\n",
      "  Embedding batch 1408-1536 of 2597...\n",
      "  Embedding batch 1536-1664 of 2597...\n",
      "  Embedding batch 1664-1792 of 2597...\n",
      "  Embedding batch 1792-1920 of 2597...\n",
      "  Embedding batch 1920-2048 of 2597...\n",
      "  Embedding batch 2048-2176 of 2597...\n",
      "  Embedding batch 2176-2304 of 2597...\n",
      "  Embedding batch 2304-2432 of 2597...\n",
      "  Embedding batch 2432-2560 of 2597...\n",
      "  Embedding batch 2560-2597 of 2597...\n",
      "\n",
      "âœ“ Saved new embeddings: (2597, 3072)\n",
      "  File: UNGA_embeddings.npy\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Generate or Load Embeddings\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load .env file from repo root\n",
    "env_path = repo_root / '.env'\n",
    "if env_path.exists():\n",
    "    load_dotenv(env_path)\n",
    "    print(f\"âœ“ Loaded .env from {env_path}\")\n",
    "else:\n",
    "    print(f\"âš  No .env file found at {env_path}\")\n",
    "\n",
    "\n",
    "def get_embeddings_from_api(texts: List[str], client) -> np.ndarray:\n",
    "    \"\"\"Call OpenAI embeddings API for a list of texts.\"\"\"\n",
    "    response = client.embeddings.create(\n",
    "        model=EMBEDDING_MODEL,\n",
    "        input=texts\n",
    "    )\n",
    "    return np.array([item.embedding for item in response.data], dtype=\"float32\")\n",
    "\n",
    "\n",
    "def generate_embeddings(texts: List[str]) -> np.ndarray:\n",
    "    \"\"\"Generate embeddings using OpenAI API.\"\"\"\n",
    "    from openai import OpenAI\n",
    "    \n",
    "    api_key = os.getenv(\"OPEN_AI_API\")\n",
    "    if not api_key:\n",
    "        raise ValueError(\n",
    "            \"OpenAI API key not found.\\n\"\n",
    "            \"Either:\\n\"\n",
    "            \"  1. Create a .env file in repo root with: OPEN_AI_API=your-key\\n\"\n",
    "            \"  2. Or set environment variable: $env:OPEN_AI_API = 'your-key'\"\n",
    "        )\n",
    "    \n",
    "    client = OpenAI(api_key=api_key)\n",
    "    all_embeddings = []\n",
    "    n = len(texts)\n",
    "    \n",
    "    for start in range(0, n, EMBEDDING_BATCH_SIZE):\n",
    "        end = min(start + EMBEDDING_BATCH_SIZE, n)\n",
    "        batch = texts[start:end]\n",
    "        print(f\"  Embedding batch {start}-{end} of {n}...\")\n",
    "        batch_embeddings = get_embeddings_from_api(batch, client)\n",
    "        all_embeddings.append(batch_embeddings)\n",
    "    \n",
    "    return np.vstack(all_embeddings)\n",
    "\n",
    "\n",
    "# Check if embeddings exist and match resolution count\n",
    "need_regenerate = False\n",
    "n_resolutions = len(resolution_df)\n",
    "\n",
    "if embeddings_path.exists() and meta_path.exists():\n",
    "    # Load existing embeddings\n",
    "    embeddings = np.load(embeddings_path)\n",
    "    with open(meta_path, 'r') as f:\n",
    "        emb_meta = json.load(f)\n",
    "    \n",
    "    print(f\"Found existing embeddings: {embeddings.shape}\")\n",
    "    print(f\"  Model: {emb_meta.get('model', 'unknown')}\")\n",
    "    print(f\"  Expected rows: {emb_meta.get('n_rows', 'unknown')}\")\n",
    "    \n",
    "    # Check if it matches current data\n",
    "    if embeddings.shape[0] != n_resolutions:\n",
    "        print(f\"\\nâš  Mismatch: embeddings have {embeddings.shape[0]} rows, data has {n_resolutions} resolutions\")\n",
    "        need_regenerate = True\n",
    "else:\n",
    "    print(\"No existing embeddings found.\")\n",
    "    need_regenerate = True\n",
    "\n",
    "if need_regenerate:\n",
    "    print(f\"\\nðŸ”„ Generating new embeddings for {n_resolutions} resolutions...\")\n",
    "    texts = resolution_df['text_clean'].tolist()\n",
    "    embeddings = generate_embeddings(texts)\n",
    "    \n",
    "    # Save embeddings\n",
    "    np.save(embeddings_path, embeddings)\n",
    "    \n",
    "    # Save metadata\n",
    "    emb_meta = {\n",
    "        \"model\": EMBEDDING_MODEL,\n",
    "        \"n_rows\": n_resolutions,\n",
    "        \"text_column\": \"title\",\n",
    "        \"generated_at\": datetime.now().isoformat()\n",
    "    }\n",
    "    with open(meta_path, 'w') as f:\n",
    "        json.dump(emb_meta, f, indent=2)\n",
    "    \n",
    "    print(f\"\\nâœ“ Saved new embeddings: {embeddings.shape}\")\n",
    "    print(f\"  File: {embeddings_path.name}\")\n",
    "else:\n",
    "    print(\"\\nâœ“ Using existing embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1634a658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running HDBSCAN clustering on embeddings...\n",
      "\n",
      "âœ“ HDBSCAN clustering complete\n",
      "  Clusters found: 98\n",
      "  Noise points: 533 (20.5%)\n",
      "\n",
      "Cluster distribution:\n",
      "cluster\n",
      "-1     533\n",
      " 90     42\n",
      " 79     41\n",
      " 21     38\n",
      " 7      37\n",
      " 37     37\n",
      " 59     35\n",
      " 26     35\n",
      " 42     33\n",
      " 40     33\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Run HDBSCAN Clustering\n",
    "\n",
    "print(\"Running HDBSCAN clustering on embeddings...\")\n",
    "\n",
    "# Create and fit HDBSCAN with same parameters as original\n",
    "clusterer = hdbscan.HDBSCAN(\n",
    "    min_cluster_size=HDBSCAN_MIN_CLUSTER_SIZE,\n",
    "    min_samples=HDBSCAN_MIN_SAMPLES,\n",
    "    metric='euclidean',\n",
    "    cluster_selection_method='eom',\n",
    "    prediction_data=True\n",
    ")\n",
    "\n",
    "cluster_labels = clusterer.fit_predict(embeddings)\n",
    "\n",
    "# Attach to dataframe\n",
    "resolution_df['cluster'] = cluster_labels\n",
    "resolution_df['cluster_prob'] = clusterer.probabilities_\n",
    "\n",
    "n_clusters = len(set(cluster_labels) - {-1})\n",
    "n_noise = (cluster_labels == -1).sum()\n",
    "\n",
    "print(f\"\\nâœ“ HDBSCAN clustering complete\")\n",
    "print(f\"  Clusters found: {n_clusters}\")\n",
    "print(f\"  Noise points: {n_noise} ({100*n_noise/len(resolution_df):.1f}%)\")\n",
    "print(f\"\\nCluster distribution:\")\n",
    "print(resolution_df['cluster'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7d469d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Generated topic labels for 99 clusters\n",
      "\n",
      "Sample labels:\n",
      "  Cluster  -1 ( 533 items): Noise / Unclustered\n",
      "  Cluster   0 (  18 items): Oil Slick Lebanese Shores\n",
      "  Cluster   1 (  11 items): Extrajudicial, Summary Arbitrary Executions\n",
      "  Cluster   2 (  11 items): Respect Universal Freedom Travel\n",
      "  Cluster   3 (  23 items): American Islands Samoa Guam\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Generate Cluster Topic Labels\n",
    "\n",
    "# For each cluster, create a simple label based on common words in titles\n",
    "# (This is a reproducible fallback; the confirmed mappings will override these)\n",
    "\n",
    "def get_cluster_label(cluster_id, df, text_col='title', max_examples=10):\n",
    "    \"\"\"Generate a simple label for a cluster based on common title words.\"\"\"\n",
    "    if cluster_id == -1:\n",
    "        return \"Noise / Unclustered\"\n",
    "    \n",
    "    cluster_texts = df[df['cluster'] == cluster_id][text_col].head(max_examples).tolist()\n",
    "    if not cluster_texts:\n",
    "        return f\"Cluster {cluster_id}\"\n",
    "    \n",
    "    # Simple word frequency approach\n",
    "    words = []\n",
    "    stop_words = {'the', 'of', 'and', 'to', 'in', 'a', 'for', 'on', 'by', 'with', 'its', 'an', 'as', 'at', 'from'}\n",
    "    for text in cluster_texts:\n",
    "        words.extend([w.lower() for w in str(text).split() if w.lower() not in stop_words and len(w) > 2])\n",
    "    \n",
    "    word_counts = Counter(words)\n",
    "    top_words = [w for w, c in word_counts.most_common(4)]\n",
    "    return ' '.join(top_words).title() if top_words else f\"Cluster {cluster_id}\"\n",
    "\n",
    "\n",
    "# Generate initial topic labels for all clusters\n",
    "cluster_ids = sorted(set(resolution_df['cluster']))\n",
    "cluster_topic_labels = {}\n",
    "\n",
    "for cl in cluster_ids:\n",
    "    cluster_topic_labels[cl] = get_cluster_label(cl, resolution_df)\n",
    "\n",
    "# Apply labels to dataframe\n",
    "resolution_df['topic_label'] = resolution_df['cluster'].map(cluster_topic_labels)\n",
    "\n",
    "print(f\"âœ“ Generated topic labels for {len(cluster_topic_labels)} clusters\")\n",
    "print(f\"\\nSample labels:\")\n",
    "for cl in list(cluster_ids)[:5]:\n",
    "    count = (resolution_df['cluster'] == cl).sum()\n",
    "    print(f\"  Cluster {cl:3d} ({count:4d} items): {cluster_topic_labels[cl]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e324056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Loaded topic mapping: topic_mapping_confirmed_all_resolutions_20251208_180017.json\n",
      "  Original mappings: 86\n",
      "  Meta-topics: 9\n",
      "\n",
      "Mapping results:\n",
      "  Exact matches: 1\n",
      "  Fuzzy matches: 40\n",
      "  Unmatched (â†’ Miscellaneous): 57\n",
      "\n",
      "Unmatched topics (assigned to Miscellaneous):\n",
      "  - Oil Slick Lebanese Shores\n",
      "  - Extrajudicial, Summary Arbitrary Executions\n",
      "  - Respect Universal Freedom Travel\n",
      "  - American Islands Samoa Guam\n",
      "  - Measures Uphold Authority 1925\n",
      "  - Financing United Nations Interim\n",
      "  - Law Sea Oceans Agreement\n",
      "  - Necessity Ending Economic, Commercial\n",
      "  - Rights Use Mercenaries Means\n",
      "  - Equitable Geographical Distribution Membership\n",
      "  ... and 47 more\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Load Confirmed Topic Mapping and Apply with Fuzzy Matching\n",
    "\n",
    "# Find the most recent confirmed topic mapping file\n",
    "topic_mapping_pattern = f\"topic_mapping_confirmed_{dataset_type}_*.json\"\n",
    "topic_mapping_file = find_latest_mapping_file(mappings_dir, topic_mapping_pattern)\n",
    "\n",
    "if topic_mapping_file is None:\n",
    "    raise FileNotFoundError(\n",
    "        f\"No topic mapping file found matching: {topic_mapping_pattern}\\n\"\n",
    "        f\"Expected in: {mappings_dir}\"\n",
    "    )\n",
    "\n",
    "topic_to_meta, topic_meta = load_mapping_json(topic_mapping_file)\n",
    "\n",
    "print(f\"âœ“ Loaded topic mapping: {Path(topic_mapping_file).name}\")\n",
    "print(f\"  Original mappings: {len(topic_to_meta)}\")\n",
    "\n",
    "# Get available meta-topics\n",
    "available_meta_topics = sorted(set(topic_to_meta.values()))\n",
    "print(f\"  Meta-topics: {len(available_meta_topics)}\")\n",
    "\n",
    "# Map new cluster labels to meta-topics using fuzzy matching\n",
    "new_topic_to_meta = {}\n",
    "unmatched_topics = []\n",
    "match_stats = {'exact': 0, 'fuzzy': 0, 'unmatched': 0}\n",
    "\n",
    "for cluster_id, new_label in cluster_topic_labels.items():\n",
    "    if cluster_id == -1:\n",
    "        continue  # Skip noise cluster\n",
    "    \n",
    "    # Try exact match first\n",
    "    if new_label in topic_to_meta:\n",
    "        new_topic_to_meta[new_label] = topic_to_meta[new_label]\n",
    "        match_stats['exact'] += 1\n",
    "    else:\n",
    "        # Try fuzzy match\n",
    "        meta_topic, confidence = fuzzy_match_topic(new_label, topic_to_meta, threshold=0.3)\n",
    "        if meta_topic:\n",
    "            new_topic_to_meta[new_label] = meta_topic\n",
    "            match_stats['fuzzy'] += 1\n",
    "        else:\n",
    "            # No match - assign to Miscellaneous\n",
    "            new_topic_to_meta[new_label] = 'Miscellaneous'\n",
    "            unmatched_topics.append(new_label)\n",
    "            match_stats['unmatched'] += 1\n",
    "\n",
    "print(f\"\\nMapping results:\")\n",
    "print(f\"  Exact matches: {match_stats['exact']}\")\n",
    "print(f\"  Fuzzy matches: {match_stats['fuzzy']}\")\n",
    "print(f\"  Unmatched (â†’ Miscellaneous): {match_stats['unmatched']}\")\n",
    "\n",
    "if unmatched_topics:\n",
    "    print(f\"\\nUnmatched topics (assigned to Miscellaneous):\")\n",
    "    for t in unmatched_topics[:10]:\n",
    "        print(f\"  - {t}\")\n",
    "    if len(unmatched_topics) > 10:\n",
    "        print(f\"  ... and {len(unmatched_topics) - 10} more\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d985db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Loaded noise mapping: noise_mapping_confirmed_all_resolutions_20251208_180624.json\n",
      "  Noise resolutions mapped: 507\n",
      "\n",
      "  Current noise points: 533\n",
      "  Mappable from existing: 176 (33.0%)\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Load Confirmed Noise Mapping (by undl_id)\n",
    "\n",
    "# Find the most recent confirmed noise mapping file\n",
    "noise_mapping_pattern = f\"noise_mapping_confirmed_{dataset_type}_*.json\"\n",
    "noise_mapping_file = find_latest_mapping_file(mappings_dir, noise_mapping_pattern)\n",
    "\n",
    "if noise_mapping_file is None:\n",
    "    print(f\"âš  No noise mapping file found. Noise items will be labeled 'Miscellaneous'.\")\n",
    "    noise_to_meta = {}\n",
    "else:\n",
    "    noise_mapping_raw, noise_meta = load_mapping_json(noise_mapping_file)\n",
    "    \n",
    "    # Handle both formats:\n",
    "    # Format 1: {\"undl_id\": \"meta_topic\", ...}\n",
    "    # Format 2: {\"0\": {\"id\": \"undl_id\", \"assigned_topic\": \"meta_topic\"}, ...}\n",
    "    noise_to_meta = {}\n",
    "    for key, value in noise_mapping_raw.items():\n",
    "        if isinstance(value, dict) and 'id' in value and 'assigned_topic' in value:\n",
    "            # Format 2\n",
    "            noise_to_meta[str(value['id'])] = value['assigned_topic']\n",
    "        elif isinstance(value, str):\n",
    "            # Format 1\n",
    "            noise_to_meta[str(key)] = value\n",
    "    \n",
    "    print(f\"âœ“ Loaded noise mapping: {Path(noise_mapping_file).name}\")\n",
    "    print(f\"  Noise resolutions mapped: {len(noise_to_meta)}\")\n",
    "\n",
    "# Count how many noise points we can map\n",
    "noise_resolutions = resolution_df[resolution_df['cluster'] == -1]['undl_id'].astype(str).tolist()\n",
    "mappable = sum(1 for uid in noise_resolutions if uid in noise_to_meta)\n",
    "print(f\"\\n  Current noise points: {len(noise_resolutions)}\")\n",
    "print(f\"  Mappable from existing: {mappable} ({100*mappable/max(1,len(noise_resolutions)):.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "898979b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying topic and noise mappings...\n",
      "  Mapped from topic labels: 2064\n",
      "  Mapped from noise (by undl_id): 176\n",
      "  Assigned to Miscellaneous: 357\n",
      "\n",
      "âœ“ Applied mappings to 2597 resolutions\n",
      "  Unique meta-topics: 10\n",
      "\n",
      "Meta-topic distribution:\n",
      "meta_topic_label\n",
      "Miscellaneous                1511\n",
      "Disarmament                   315\n",
      "Israel/Palestine Conflict     298\n",
      "Human Rights                  202\n",
      "Development                   146\n",
      "Displacement                   61\n",
      "International Cooperation      50\n",
      "International Law               9\n",
      "Human Rights in CRINK           4\n",
      "Economic Sanctions              1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Apply Mappings to Create Meta-Topic Column\n",
    "\n",
    "print(\"Applying topic and noise mappings...\")\n",
    "\n",
    "# Initialize meta_topic_label column\n",
    "resolution_df['meta_topic_label'] = None\n",
    "\n",
    "# Step 1: Apply topic-to-meta mapping for clustered (non-noise) rows\n",
    "mapped_from_topic = 0\n",
    "for new_label, meta_topic in new_topic_to_meta.items():\n",
    "    mask = resolution_df['topic_label'] == new_label\n",
    "    resolution_df.loc[mask, 'meta_topic_label'] = meta_topic\n",
    "    mapped_from_topic += mask.sum()\n",
    "\n",
    "print(f\"  Mapped from topic labels: {mapped_from_topic}\")\n",
    "\n",
    "# Step 2: Apply noise-to-meta mapping for noise rows (by undl_id)\n",
    "mapped_from_noise = 0\n",
    "if noise_to_meta:\n",
    "    for idx, row in resolution_df[resolution_df['cluster'] == -1].iterrows():\n",
    "        undl_id_str = str(row['undl_id'])\n",
    "        if undl_id_str in noise_to_meta:\n",
    "            resolution_df.loc[idx, 'meta_topic_label'] = noise_to_meta[undl_id_str]\n",
    "            mapped_from_noise += 1\n",
    "\n",
    "print(f\"  Mapped from noise (by undl_id): {mapped_from_noise}\")\n",
    "\n",
    "# Step 3: Fill remaining nulls with 'Miscellaneous'\n",
    "unmapped = resolution_df['meta_topic_label'].isna().sum()\n",
    "resolution_df['meta_topic_label'] = resolution_df['meta_topic_label'].fillna('Miscellaneous')\n",
    "print(f\"  Assigned to Miscellaneous: {unmapped}\")\n",
    "\n",
    "# Create numeric meta_topic_id\n",
    "unique_meta_topics = sorted(resolution_df['meta_topic_label'].unique())\n",
    "meta_topic_id_map = {mt: i for i, mt in enumerate(unique_meta_topics)}\n",
    "resolution_df['meta_topic_id'] = resolution_df['meta_topic_label'].map(meta_topic_id_map)\n",
    "\n",
    "print(f\"\\nâœ“ Applied mappings to {len(resolution_df)} resolutions\")\n",
    "print(f\"  Unique meta-topics: {len(unique_meta_topics)}\")\n",
    "print(f\"\\nMeta-topic distribution:\")\n",
    "print(resolution_df['meta_topic_label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c779cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CRINK voting alignment...\n",
      "\n",
      "âœ“ Calculated alignment for 2597 resolutions\n",
      "\n",
      "Alignment summary:\n",
      "  4-way alignment (all 4 CRINK): 1373\n",
      "  3-way alignment (3 of 4 CRINK): 793\n",
      "  2-way alignment (2 of 4 CRINK): 401\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Calculate CRINK Voting Alignment by Resolution\n",
    "\n",
    "print(\"Calculating CRINK voting alignment...\")\n",
    "\n",
    "# Get CRINK country votes for each resolution\n",
    "crink_names = list(CRINK_COUNTRIES.keys())\n",
    "crink_codes = list(CRINK_COUNTRIES.values())\n",
    "\n",
    "# Pivot to get one column per CRINK country\n",
    "crink_votes_df = df[df['ms_name'].isin(crink_names)].pivot_table(\n",
    "    index='undl_id',\n",
    "    columns='ms_name',\n",
    "    values='ms_vote',\n",
    "    aggfunc='first'\n",
    ").reset_index()\n",
    "\n",
    "# Merge with resolution_df\n",
    "resolution_df = resolution_df.merge(crink_votes_df, on='undl_id', how='left')\n",
    "\n",
    "# Calculate alignment metrics\n",
    "def calculate_crink_alignment(row):\n",
    "    \"\"\"Calculate how many CRINK countries voted together.\"\"\"\n",
    "    votes = [row.get(c) for c in crink_names if c in row.index and pd.notna(row.get(c))]\n",
    "    \n",
    "    if len(votes) < 2:\n",
    "        return pd.Series({\n",
    "            'crink_votes_available': len(votes),\n",
    "            'max_agreement_count': 0,\n",
    "            'four_vote_alignment': 0,\n",
    "            'three_vote_alignment': 0,\n",
    "            'two_vote_alignment': 0,\n",
    "            'crink_group_vote': None\n",
    "        })\n",
    "    \n",
    "    vote_counts = Counter(votes)\n",
    "    most_common_vote, max_count = vote_counts.most_common(1)[0]\n",
    "    \n",
    "    return pd.Series({\n",
    "        'crink_votes_available': len(votes),\n",
    "        'max_agreement_count': max_count,\n",
    "        'four_vote_alignment': 1 if max_count == 4 else 0,\n",
    "        'three_vote_alignment': 1 if max_count == 3 else 0,\n",
    "        'two_vote_alignment': 1 if max_count == 2 else 0,\n",
    "        'crink_group_vote': most_common_vote\n",
    "    })\n",
    "\n",
    "alignment_results = resolution_df.apply(calculate_crink_alignment, axis=1)\n",
    "resolution_df = pd.concat([resolution_df, alignment_results], axis=1)\n",
    "\n",
    "print(f\"\\nâœ“ Calculated alignment for {len(resolution_df)} resolutions\")\n",
    "print(f\"\\nAlignment summary:\")\n",
    "print(f\"  4-way alignment (all 4 CRINK): {resolution_df['four_vote_alignment'].sum()}\")\n",
    "print(f\"  3-way alignment (3 of 4 CRINK): {resolution_df['three_vote_alignment'].sum()}\")\n",
    "print(f\"  2-way alignment (2 of 4 CRINK): {resolution_df['two_vote_alignment'].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb28b7b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Added US vote and UN majority alignment\n",
      "  CRINK against US: 2219 resolutions\n",
      "  CRINK with UN majority: 2117 resolutions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lucian\\AppData\\Local\\Temp\\ipykernel_22520\\3287003252.py:25: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  majority_votes = df.groupby('undl_id').apply(get_majority_vote).reset_index()\n"
     ]
    }
   ],
   "source": [
    "# Cell 11: Add US Vote and UN Majority Alignment\n",
    "\n",
    "# Get US votes\n",
    "us_votes = df[df['ms_name'] == 'UNITED STATES'][['undl_id', 'ms_vote']].rename(\n",
    "    columns={'ms_vote': 'us_vote'}\n",
    ").drop_duplicates('undl_id')\n",
    "\n",
    "resolution_df = resolution_df.merge(us_votes, on='undl_id', how='left')\n",
    "\n",
    "# Calculate CRINK against US\n",
    "resolution_df['crink_against_us'] = (\n",
    "    (resolution_df['crink_group_vote'] != resolution_df['us_vote']) &\n",
    "    resolution_df['crink_group_vote'].notna() &\n",
    "    resolution_df['us_vote'].notna() &\n",
    "    (resolution_df['max_agreement_count'] >= 2)\n",
    ").astype(int)\n",
    "\n",
    "# Calculate UN majority vote per resolution\n",
    "def get_majority_vote(group):\n",
    "    votes = group['ms_vote'].dropna()\n",
    "    if len(votes) == 0:\n",
    "        return None\n",
    "    return votes.mode().iloc[0] if len(votes.mode()) > 0 else None\n",
    "\n",
    "majority_votes = df.groupby('undl_id').apply(get_majority_vote).reset_index()\n",
    "majority_votes.columns = ['undl_id', 'un_majority_vote']\n",
    "\n",
    "resolution_df = resolution_df.merge(majority_votes, on='undl_id', how='left')\n",
    "\n",
    "# Calculate CRINK with majority\n",
    "resolution_df['crink_with_majority'] = (\n",
    "    (resolution_df['crink_group_vote'] == resolution_df['un_majority_vote']) &\n",
    "    resolution_df['crink_group_vote'].notna() &\n",
    "    (resolution_df['max_agreement_count'] >= 2)\n",
    ").astype(int)\n",
    "\n",
    "print(f\"âœ“ Added US vote and UN majority alignment\")\n",
    "print(f\"  CRINK against US: {resolution_df['crink_against_us'].sum()} resolutions\")\n",
    "print(f\"  CRINK with UN majority: {resolution_df['crink_with_majority'].sum()} resolutions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59d3b41d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating topic alignment summary table...\n",
      "\n",
      "====================================================================================================\n",
      "CRINK VOTING ALIGNMENT BY META-TOPIC (UNGA)\n",
      "Total resolutions: 2597\n",
      "Sorted by 4-way alignment (all CRINK countries vote together)\n",
      "====================================================================================================\n",
      "\n",
      " Rank                Meta-Topic    N  4-Way %  3-Way %  2-Way %  vs US %  w/ Majority %\n",
      "    1        Economic Sanctions    1    100.0      0.0      0.0    100.0          100.0\n",
      "    2 Israel/Palestine Conflict  298     76.2     22.8      1.0    100.0           99.7\n",
      "    3 International Cooperation   50     76.0     14.0     10.0     84.0           92.0\n",
      "    4               Development  146     73.3     12.3     12.3     87.7           93.8\n",
      "    5              Displacement   61     54.1     11.5     34.4     96.7           60.7\n",
      "    6     Human Rights in CRINK    4     50.0     50.0      0.0    100.0          100.0\n",
      "    7             Miscellaneous 1511     49.7     33.6     15.8     83.4           83.5\n",
      "    8              Human Rights  202     49.0     22.3     25.2     88.6           51.0\n",
      "    9         International Law    9     44.4     22.2     33.3     88.9           55.6\n",
      "   10               Disarmament  315     35.2     43.2     19.4     76.2           71.4\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Column definitions:\n",
      "  4-Way %: Share of resolutions where all 4 CRINK vote the same\n",
      "  3-Way %: Share where 3 of 4 CRINK vote the same\n",
      "  2-Way %: Share where 2 of 4 CRINK vote the same\n",
      "  vs US %: Share where CRINK majority voted against US\n",
      "  w/ Majority %: Share where CRINK majority aligned with UN majority\n"
     ]
    }
   ],
   "source": [
    "# Cell 12: Generate Topic Alignment Summary Table\n",
    "\n",
    "print(\"Generating topic alignment summary table...\\n\")\n",
    "\n",
    "# Aggregate by meta-topic\n",
    "topic_summary = resolution_df.groupby('meta_topic_label').agg(\n",
    "    n_resolutions=('undl_id', 'count'),\n",
    "    four_way_count=('four_vote_alignment', 'sum'),\n",
    "    three_way_count=('three_vote_alignment', 'sum'),\n",
    "    two_way_count=('two_vote_alignment', 'sum'),\n",
    "    against_us_count=('crink_against_us', 'sum'),\n",
    "    with_majority_count=('crink_with_majority', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# Calculate percentages\n",
    "topic_summary['four_way_pct'] = (100 * topic_summary['four_way_count'] / topic_summary['n_resolutions']).round(1)\n",
    "topic_summary['three_way_pct'] = (100 * topic_summary['three_way_count'] / topic_summary['n_resolutions']).round(1)\n",
    "topic_summary['two_way_pct'] = (100 * topic_summary['two_way_count'] / topic_summary['n_resolutions']).round(1)\n",
    "topic_summary['against_us_pct'] = (100 * topic_summary['against_us_count'] / topic_summary['n_resolutions']).round(1)\n",
    "topic_summary['with_majority_pct'] = (100 * topic_summary['with_majority_count'] / topic_summary['n_resolutions']).round(1)\n",
    "\n",
    "# Sort by 4-way alignment\n",
    "topic_summary = topic_summary.sort_values('four_way_pct', ascending=False).reset_index(drop=True)\n",
    "topic_summary['rank'] = range(1, len(topic_summary) + 1)\n",
    "\n",
    "# Select display columns\n",
    "display_cols = [\n",
    "    'rank', 'meta_topic_label', 'n_resolutions',\n",
    "    'four_way_pct', 'three_way_pct', 'two_way_pct',\n",
    "    'against_us_pct', 'with_majority_pct'\n",
    "]\n",
    "\n",
    "display_df = topic_summary[display_cols].copy()\n",
    "display_df.columns = [\n",
    "    'Rank', 'Meta-Topic', 'N',\n",
    "    '4-Way %', '3-Way %', '2-Way %',\n",
    "    'vs US %', 'w/ Majority %'\n",
    "]\n",
    "\n",
    "print(\"=\" * 100)\n",
    "print(\"CRINK VOTING ALIGNMENT BY META-TOPIC (UNGA)\")\n",
    "print(f\"Total resolutions: {len(resolution_df)}\")\n",
    "print(\"Sorted by 4-way alignment (all CRINK countries vote together)\")\n",
    "print(\"=\" * 100)\n",
    "print()\n",
    "print(display_df.to_string(index=False))\n",
    "print()\n",
    "print(\"=\" * 100)\n",
    "print(\"\\nColumn definitions:\")\n",
    "print(\"  4-Way %: Share of resolutions where all 4 CRINK vote the same\")\n",
    "print(\"  3-Way %: Share where 3 of 4 CRINK vote the same\")\n",
    "print(\"  2-Way %: Share where 2 of 4 CRINK vote the same\")\n",
    "print(\"  vs US %: Share where CRINK majority voted against US\")\n",
    "print(\"  w/ Majority %: Share where CRINK majority aligned with UN majority\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "deb40583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Saved: Table2_Topic_Distribution_CRINK_Fully_Aligned_UNGA_20260109.csv\n",
      "âœ“ Saved: resolutions_with_metatopics_UNGA_20260109.csv\n",
      "âœ“ Saved: Table2_Topic_Distribution_CRINK_Fully_Aligned_UNGA.tex\n",
      "\n",
      "============================================================\n",
      "ALL RESULTS SAVED\n",
      "============================================================\n",
      "\n",
      "Output files in: c:\\Users\\Lucian\\OneDrive - Tulane University\\01 IFSH\\Data Sciences try\\measuring-CRINK-alignment-UN\\results\n",
      "\n",
      "Table 2: Topic Distribution of Resolutions where CRINK States Fully Aligned in the UNGA Plenary, 1991-2024\n"
     ]
    }
   ],
   "source": [
    "# Cell 13: Save Results\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d')\n",
    "\n",
    "# Table naming for publication\n",
    "TABLE_NAME = \"Table2_Topic_Distribution_CRINK_Fully_Aligned\"\n",
    "TABLE_CAPTION = \"Topic Distribution of Resolutions where CRINK States Fully Aligned in the UNGA Plenary, 1991-2024\"\n",
    "\n",
    "# Save summary table as CSV\n",
    "summary_csv = results_dir / f'{TABLE_NAME}_UNGA_{timestamp}.csv'\n",
    "topic_summary.to_csv(summary_csv, index=False)\n",
    "print(f\"âœ“ Saved: {summary_csv.name}\")\n",
    "\n",
    "# Save full resolution data with meta-topics\n",
    "full_csv = results_dir / f'resolutions_with_metatopics_UNGA_{timestamp}.csv'\n",
    "export_cols = ['undl_id', 'title', 'date', 'year', 'cluster', 'topic_label', \n",
    "               'meta_topic_label', 'meta_topic_id', 'crink_group_vote',\n",
    "               'max_agreement_count', 'four_vote_alignment', 'three_vote_alignment',\n",
    "               'two_vote_alignment', 'crink_against_us', 'crink_with_majority']\n",
    "export_cols = [c for c in export_cols if c in resolution_df.columns]\n",
    "resolution_df[export_cols].to_csv(full_csv, index=False)\n",
    "print(f\"âœ“ Saved: {full_csv.name}\")\n",
    "\n",
    "# Generate LaTeX table\n",
    "def generate_latex_table(df_table, caption, label):\n",
    "    \"\"\"Generate LaTeX table with academic formatting.\"\"\"\n",
    "    df_clean = df_table.drop(columns=['Rank']) if 'Rank' in df_table.columns else df_table.copy()\n",
    "    \n",
    "    # Build LaTeX\n",
    "    n_cols = len(df_clean.columns)\n",
    "    col_spec = 'l' + 'r' * (n_cols - 1)\n",
    "    \n",
    "    latex = f\"\"\"\\\\begin{{table}}[htbp]\n",
    "\\\\centering\n",
    "\\\\footnotesize\n",
    "\\\\begin{{tabular}}{{{col_spec}}}\n",
    "\\\\hline\n",
    "\"\"\"\n",
    "    \n",
    "    # Header\n",
    "    headers = [c.replace('%', '\\\\%').replace('_', ' ') for c in df_clean.columns]\n",
    "    latex += ' & '.join([f'\\\\textbf{{{h}}}' for h in headers]) + ' \\\\\\\\\\n'\n",
    "    latex += '\\\\hline\\n'\n",
    "    \n",
    "    # Data rows\n",
    "    for _, row in df_clean.iterrows():\n",
    "        values = []\n",
    "        for col in df_clean.columns:\n",
    "            val = row[col]\n",
    "            if isinstance(val, float):\n",
    "                values.append(f'{val:.1f}')\n",
    "            else:\n",
    "                values.append(str(val).replace('&', '\\\\&').replace('%', '\\\\%'))\n",
    "        latex += ' & '.join(values) + ' \\\\\\\\\\n'\n",
    "    \n",
    "    latex += f\"\"\"\\\\hline\n",
    "\\\\end{{tabular}}\n",
    "\\\\caption{{{caption}}}\n",
    "\\\\label{{{label}}}\n",
    "\\\\end{{table}}\n",
    "\"\"\"\n",
    "    return latex\n",
    "\n",
    "latex_table = generate_latex_table(display_df, TABLE_CAPTION, \"tab:table2_topic_distribution\")\n",
    "\n",
    "latex_file = results_dir / f'{TABLE_NAME}_UNGA.tex'\n",
    "with open(latex_file, 'w', encoding='utf-8') as f:\n",
    "    f.write(latex_table)\n",
    "print(f\"âœ“ Saved: {latex_file.name}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"ALL RESULTS SAVED\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"\\nOutput files in: {results_dir}\")\n",
    "print(f\"\\nTable 2: {TABLE_CAPTION}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424b3ac2",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook has:\n",
    "1. Loaded UN voting data (5,415 unique resolutions, 1946-2024)\n",
    "2. Generated or loaded embeddings using OpenAI's `text-embedding-3-large` model\n",
    "3. Run HDBSCAN clustering to assign resolutions to topic clusters\n",
    "4. Applied confirmed topic mappings using fuzzy matching to reuse existing meta-topic assignments\n",
    "5. Assigned noise resolutions to meta-topics using undl_id-based mapping\n",
    "6. Calculated CRINK voting alignment metrics (4-way, 3-way, 2-way, vs US, with UN majority)\n",
    "7. Generated summary tables for publication\n",
    "\n",
    "### Mapping Reuse Strategy\n",
    "- **Topic mappings**: Fuzzy word-overlap matching to map new cluster labels â†’ existing meta-topics\n",
    "- **Noise mappings**: Direct undl_id lookup (works for overlapping resolutions)\n",
    "- **Unmatched items**: Assigned to \"Miscellaneous\" category\n",
    "\n",
    "### Reproducibility Notes\n",
    "- Embeddings are saved to `data/mappings/UNGA_embeddings.npy`\n",
    "- HDBSCAN parameters: `min_cluster_size=10`, `min_samples=1`\n",
    "- Requires `OPEN_AI_API` environment variable for embedding generation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Webscraping",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
